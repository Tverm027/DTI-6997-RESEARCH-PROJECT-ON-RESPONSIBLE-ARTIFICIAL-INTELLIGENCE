TY  - CONF
TI  - AI-automated Cephalometric Tracing: A New Normal in Orthodontics?
T2  - 2024 International Conference on Artificial Intelligence, Computer, Data Sciences and Applications (ACDSA)
SP  - 1
EP  - 4
AU  - M. Strunga
AU  - D. S. Ballová
AU  - J. Tomášik
AU  - Ľ. Oravcová
AU  - Ľ. Danišovič
AU  - A. Thurzo
PY  - 2024
KW  - Radiography
KW  - Three-dimensional displays
KW  - Computed tomography
KW  - Observers
KW  - Software
KW  - Planning
KW  - Artificial intelligence
KW  - artificial intelligence
KW  - treatment planning
KW  - CBCT
KW  - machine learning
KW  - cephalometric analysis
DO  - 10.1109/ACDSA59508.2024.10467825
JO  - 2024 International Conference on Artificial Intelligence, Computer, Data Sciences and Applications (ACDSA)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2024 International Conference on Artificial Intelligence, Computer, Data Sciences and Applications (ACDSA)
Y1  - 1-2 Feb. 2024
AB  - Cephalometric analysis has typically been used to evaluate lateral skull radiographs taken with a cephalostat to determine the skeletal pattern and assess treatment difficulties in orthodontics. Nowadays, Cone beam computed tomography (CBCT) data can be used for 3D cephalometrics. This study compares the performance of AI-automated cephalometric tracing with human-operated digital tracing using the Invivo 7.1.2 software on a sample of 120 scans evaluated by 5 observers (4 human and AI) for 14 cephalometric variables. Measurements were repeated for paired tests. ANOVA was used to minimize type I error. Normality of the data was tested using the Shapiro-Wilk test. The Wilcoxon test was used to compare measurement times between humans and AI. This study found that there were statistically significant differences between human observers and AI in 6 of 14 variables. The AI measurements were higher than the human measurements for these variables. The duration of measurements was also statistically significantly shorter for human observers than for AI. Now at the dawn of an era of AI-assisted diagnostics, we temporarily experience translational period of AI-automated algorithms being less accurate and slower than humans, albeit they will likely become the new normal in orthodontic treatment planning. This study also highlights the importance of rigorous scientific evaluation by independent researchers of incoming AI-automated cephalometric tracing solutions before they are considered clinically appropriate.
ER  - 

TY  - CONF
TI  - AI Techniques for Cone Beam Computed Tomography in Dentistry: Trends and Practices
T2  - 2023 International Conference on Recent Advances in Electrical, Electronics & Digital Healthcare Technologies (REEDCON)
SP  - 226
EP  - 231
AU  - S. Sarwar
AU  - S. Jabin
PY  - 2023
KW  - Machine learning algorithms
KW  - Computed tomography
KW  - Imaging
KW  - Teeth
KW  - Transforms
KW  - Market research
KW  - Bones
KW  - Artificial Intelligence
KW  - CBCT
KW  - Deep Learning
KW  - Image Analysis
KW  - Dentistry
DO  - 10.1109/REEDCON57544.2023.10151069
JO  - 2023 International Conference on Recent Advances in Electrical, Electronics & Digital Healthcare Technologies (REEDCON)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2023 International Conference on Recent Advances in Electrical, Electronics & Digital Healthcare Technologies (REEDCON)
Y1  - 1-3 May 2023
AB  - Cone-beam computed tomography (CBCT) is a popular imaging modality in dentistry for diagnosing and planning treatment for a variety of oral diseases with the ability to produce detailed, three-dimensional images of the teeth, jawbones, and surrounding structures. CBCT imaging has emerged as an essential diagnostic tool in dentistry. CBCT imaging has seen significant improvements in terms of its diagnostic value, as well as its accuracy and efficiency, with the most recent development of artificial intelligence (AI) techniques. This paper reviews recent AI trends and practices in dental CBCT imaging. AI has been used for lesion detection, malocclusion classification, measurement of buccal bone thickness, and classification and segmentation of teeth, alveolar bones, mandibles, landmarks, contours, and pharyngeal airways using CBCT images. Mainly machine learning algorithms, deep learning algorithms, and super-resolution techniques are used for these tasks. This review focuses on the potential of AI techniques to transform CBCT imaging in dentistry, which would improve both diagnosis and treatment planning. Finally, we discuss the challenges and limitations of artificial intelligence in dentistry and CBCT imaging.
ER  - 

TY  - JOUR
TI  - Two-Stage Mesh Deep Learning for Automated Tooth Segmentation and Landmark Localization on 3D Intraoral Scans
T2  - IEEE Transactions on Medical Imaging
SP  - 3158
EP  - 3166
AU  - T. -H. Wu
AU  - C. Lian
AU  - S. Lee
AU  - M. Pastewait
AU  - C. Piers
AU  - J. Liu
AU  - F. Wang
AU  - L. Wang
AU  - C. -Y. Chiu
AU  - W. Wang
AU  - C. Jackson
AU  - W. -L. Chao
AU  - D. Shen
AU  - C. -C. Ko
PY  - 2022
KW  - Teeth
KW  - Dentistry
KW  - Three-dimensional displays
KW  - Location awareness
KW  - Task analysis
KW  - Solid modeling
KW  - Heating systems
KW  - Tooth segmentation
KW  - anatomical landmark detection
KW  - orthodontic treatment planning
KW  - 3D deep learning
KW  - intraoral scan
DO  - 10.1109/TMI.2022.3180343
JO  - IEEE Transactions on Medical Imaging
IS  - 11
SN  - 1558-254X
VO  - 41
VL  - 41
JA  - IEEE Transactions on Medical Imaging
Y1  - Nov. 2022
AB  - Accurately segmenting teeth and identifying the corresponding anatomical landmarks on dental mesh models are essential in computer-aided orthodontic treatment. Manually performing these two tasks is time-consuming, tedious, and, more importantly, highly dependent on orthodontists’ experiences due to the abnormality and large-scale variance of patients’ teeth. Some machine learning-based methods have been designed and applied in the orthodontic field to automatically segment dental meshes (e.g., intraoral scans). In contrast, the number of studies on tooth landmark localization is still limited. This paper proposes a two-stage framework based on mesh deep learning (called TS-MDL) for joint tooth labeling and landmark identification on raw intraoral scans. Our TS-MDL first adopts an end-to-end iMeshSegNet method (i.e., a variant of the existing MeshSegNet with both improved accuracy and efficiency) to label each tooth on the downsampled scan. Guided by the segmentation outputs, our TS-MDL further selects each tooth’s region of interest (ROI) on the original mesh to construct a light-weight variant of the pioneering PointNet (i.e., PointNet-Reg) for regressing the corresponding landmark heatmaps. Our TS-MDL was evaluated on a real-clinical dataset, showing promising segmentation and localization performance. Specifically, iMeshSegNet in the first stage of TS-MDL reached an averaged Dice similarity coefficient (DSC) at  ${0.964}\pm {0.054}$ , significantly outperforming the original MeshSegNet. In the second stage, PointNet-Reg achieved a mean absolute error (MAE) of  ${0}.{597}\pm {0}.{761} \, mm$  in distances between the prediction and ground truth for 66 landmarks, which is superior compared with other networks for landmark detection. All these results suggest the potential usage of our TS-MDL in orthodontics.
ER  - 

TY  - CONF
TI  - “Constructing Machine Learning models for Orthodontic Treatment Planning: a comparison of different methods”
T2  - 2022 IEEE International Conference on Big Data (Big Data)
SP  - 2790
EP  - 2799
AU  - H. Shojaei
AU  - V. Augusto
PY  - 2022
KW  - Support vector machines
KW  - Neural networks
KW  - Big Data
KW  - Feature extraction
KW  - Dentistry
KW  - Planning
KW  - Task analysis
KW  - digital dentistry
KW  - Machine Learning in dentistry
KW  - Orthodontics
KW  - treatment planning
KW  - AI in dentistry
DO  - 10.1109/BigData55660.2022.10021045
JO  - 2022 IEEE International Conference on Big Data (Big Data)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2022 IEEE International Conference on Big Data (Big Data)
Y1  - 17-20 Dec. 2022
AB  - Objective: In this study, we investigated the feasibility of leveraging different machine learning methods to help with clinical decision-making on orthodontic treatment planning, including the decision on extraction, extraction pattern and anchorage pattern.Setting and Sample Population: a group of 216 patients (156 extraction and 60 non-extraction) was enrolled.Materials and Methods: 32 input features were identified and used as the input variable. We proposed 7 machine learning methods including Logistic Regression, SVM, Decision Tree, Random Forest, Gaussian NB, KNN Classifier and Neural Network for extraction and 2 methods including Random forest and Neural Network for extraction and anchorage pattern.Results: For extraction decision, neural network yielded the most promising results by 93 % accuracy followed by Logistic regression (86 % accuracy and 93% precision), SVM and Random Forest (83 % accuracy and 90% precision). Naïve Bayesian classifier and KNN classifier failed to produce accuracy within the acceptable range but Naïve Bayes demonstrated the highest recall score with 92 %. For the decision on extraction & anchorage pattern neural network proved to be more reliable with 89 % accuracy on extraction pattern and 81% accuracy on extraction&amp; anchorage pattern. Random Forest classifier with 41% accuracy did not show satisfactory results for this task. The most important features for decision on extraction in this study were Inter incisal angle, crowding in mandible, U1-FH, L1-NB and crowding in maxilla.Conclusion: The results demonstrate that neural network can yield considerable accuracy in a medical diagnosis model. However, other algorithms such as logistic regression and random forest can also be considered for simpler tasks such as extraction.
ER  - 

TY  - CONF
TI  - Automatic Tooth Enumeration on Panoramic Radiographs Using Deep Learning
T2  - 2023 IEEE 9th International Conference on Computing, Engineering and Design (ICCED)
SP  - 1
EP  - 6
AU  - A. Fariza
AU  - R. Asmara
AU  - M. O. F. Rojaby
AU  - E. R. Astuti
AU  - R. H. Putra
PY  - 2023
KW  - YOLO
KW  - Computational modeling
KW  - Teeth
KW  - Predictive models
KW  - Dentistry
KW  - Planning
KW  - Diagnostic radiography
KW  - Tooth enumeration
KW  - panoramic radiographs
KW  - YOLOv5
KW  - deep learning
DO  - 10.1109/ICCED60214.2023.10424999
JO  - 2023 IEEE 9th International Conference on Computing, Engineering and Design (ICCED)
IS  - 
SN  - 2767-7826
VO  - 
VL  - 
JA  - 2023 IEEE 9th International Conference on Computing, Engineering and Design (ICCED)
Y1  - 7-8 Nov. 2023
AB  - Accurate tooth numbering is essential for dental procedures, treatment planning, and patient record management. Automatic tooth enumeration in dental panoramic radiographs is crucial in modern dental image analysis and diagnosis. Tooth enumeration in panoramic radiographs has relied on handcrafted features and traditional image processing techniques. Still, these methods often lack the accuracy and robustness required for complex cases and varied image qualities. Despite the advancements in deep learning-based object detection algorithms, a significant research gap remains in the specific domain of automatic tooth enumeration on panoramic radiographs. This research paper presents an innovative approach for automatic tooth enumeration on panoramic radiographs using the state-of-the-art You Only Look Once (YOLO) object detection framework focused on implementing the YOLOv5 library. The YOLOv5 model is evaluated as an efficient system capable of accurately detecting and enumerating individual teeth from panoramic radiographs. The 612 panoramic radiograph images evaluation shows the bounding-box results show the best tooth detection rate in the YOLOv5x model. The YOLOv5 model is generally very good at predicting tooth enumeration on panoramic radiographs in a relatively small dataset. This advancement is expected to enhance dental diagnosis and treatment planning, benefiting dental professionals and patients.
ER  - 

TY  - CONF
TI  - Utilizing Nlp And Machine Learning To Predict Patient Outcomes From Electronic Health Records In Cloud Environments
T2  - 2023 International Conference on Artificial Intelligence for Innovations in Healthcare Industries (ICAIIHI)
SP  - 1
EP  - 7
AU  - K. Ravindar
AU  - M. Gupta
AU  - D. S. Abdul-Zahra
AU  - N. Maiti
AU  - R. Chawla
AU  - K. S. Prashanth
PY  - 2023
KW  - Industries
KW  - Technological innovation
KW  - Statistical analysis
KW  - Scalability
KW  - Machine learning
KW  - Medical services
KW  - Predictive models
KW  - Cloud-Based the Environment
KW  - Medicine
KW  - the Processing of Natural Language
KW  - Artificial Intelligence
KW  - Predictive Analytics
DO  - 10.1109/ICAIIHI57871.2023.10489152
JO  - 2023 International Conference on Artificial Intelligence for Innovations in Healthcare Industries (ICAIIHI)
IS  - 
SN  - 
VO  - 1
VL  - 1
JA  - 2023 International Conference on Artificial Intelligence for Innovations in Healthcare Industries (ICAIIHI)
Y1  - 29-30 Dec. 2023
AB  - In stored in the cloud healthcare systems, this research investigates the incorporation of machine learning (ML) along with natural language processing (NLP) for statistical analysis employing electronic health records (EHRs). Using a design based on description and additional data collection, our own deductive approach adopts an interpretivist framework. Unstructured medical writing can yield insights that NLP techniques can use to inform the creation of machine learning models that are predictive. The outcomes demonstrate how well ML models perform in predicting patient outcomes and how useful NLP is in structuring EHR data. The study tackles cloud-based setting scalability issues and highlights the ability to interpret models by means of SHAP values.
ER  - 

TY  - CONF
TI  - Open source image processing module to improve dental patient care in suburban and rural areas: Review Paper
T2  - 2023 14th International Conference on Computing Communication and Networking Technologies (ICCCNT)
SP  - 1
EP  - 12
AU  - S. M. Shukla
AU  - G. Mishra
AU  - R. Mishra
PY  - 2023
KW  - Schedules
KW  - Image processing
KW  - Teeth
KW  - Organizations
KW  - Software
KW  - Dentistry
KW  - Medical diagnosis
KW  - Dental imaging
KW  - dental treatment planning
KW  - dental image processing tools
KW  - oral health imaging
KW  - dental radiography
KW  - dental image analysis
KW  - the module of image processing
KW  - Exposed source image dispensation
KW  - Model of the neural network
KW  - healthcare facilities
KW  - rural area
KW  - suburban areas
KW  - computer vision library
KW  - Artificial Intelligence
KW  - Commercial based software
KW  - Open source-based software
DO  - 10.1109/ICCCNT56998.2023.10307967
JO  - 2023 14th International Conference on Computing Communication and Networking Technologies (ICCCNT)
IS  - 
SN  - 2473-7674
VO  - 
VL  - 
JA  - 2023 14th International Conference on Computing Communication and Networking Technologies (ICCCNT)
Y1  - 6-8 July 2023
AB  - The study paper showcases a detailed study of dental imaging can be possible only under the technology of open-source image processing modules as it involves the use of the latest image processing tools and devices for improving both the quality and accuracy of dental images. Dental radiography delivers significant indications for medical diagnosis, treatment and superiority valuation. Many determinations have been prepared to mature numeral X-ray image investigation organizations to progress medical eminence. This paper has presented records, techniques, and consequences for assessing the superiority of dental caution-consuming circumferential dental radiographs occupied earlier and afterwards the technique. Dental experimental eminence assessment comprises many procedures, such as statistics of yearly dental appointments of kids and grownups of dissimilar eternities, different caries between kids with vigorous caries, endodontics to abstraction events etc. This eminence extent evaluates dental scientific superiority. At the macro level, It is needed to escalate the micro level equally well, such as thoughtful whether the treatment assumed to distinct teeth is operative or not. The original and developing ground in orthodonture is dental informatics, owing to its possibility to recover treatment and analysis, while exchangeable time and plummeting nervousness and exhaustion throughout the regular repetition. The usage of computer curriculums can comfort dental specialists in the creation of conclusions associated with deterrence, identification, as well as cure schedule, surrounded by others. This study paper will also discuss the efficiency of Image processing tools that help a dentist and dental professionals improve the treatment quality.
ER  - 

TY  - CONF
TI  - Automatic Cephalometric Analysis using Machine Learning
T2  - 2022 2nd International Conference on Intelligent Technologies (CONIT)
SP  - 1
EP  - 5
AU  - M. Sobhana
AU  - K. R. Vemulapalli
AU  - L. Appala
AU  - N. Narra
PY  - 2022
KW  - Shape
KW  - Sociology
KW  - Teeth
KW  - Machine learning
KW  - Software
KW  - Planning
KW  - Dentistry
KW  - Orthodontics
KW  - Malocclusions
KW  - Radiographs
KW  - Cephalometrics
KW  - Diagnosis
KW  - Decision Trees
DO  - 10.1109/CONIT55038.2022.9848060
JO  - 2022 2nd International Conference on Intelligent Technologies (CONIT)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2022 2nd International Conference on Intelligent Technologies (CONIT)
Y1  - 24-26 June 2022
AB  - Orthodontics is a specialized dental profession that specializes in diagnosing, preventing, and correcting teeth and jawbone, as well as biting patterns. The irregular shape of the teeth and jaws is very common. About 50% of the population of the developed world, according to the American Association of Orthodontics, has malocclusions heavy enough to benefit from orthopedic treatment. Cephalometries is often used by dentists as a tool for diagnosis and treatment planning and evaluation. Cephalometries aids in orthodontic diagnostics by empowering the study of skeletal structures, teeth, and soft tissues of the craniofacial region. Cephalometric analysis has many applications, including diagnostics, the definition of face measurement patterns, planning of orthodontic and orthognathic treatments, monitoring changes due to ageing or treatment and prediction of orthodontic and orthognathic treatment outcomes. Machine-based software is the only solution to reduce the dentist's work of planning and evaluation. Although some software are available for cephalometric analysis but, they are expensive and not easy to use as it requires heavy hardware-based tools such as laser guns and cephalostats. The proposed model uses a decision tree to develop a diagnostic program based on the data of previous patients assigned to it. This model is implemented using python language libraries such as Tkinter, Opencv, Sklearn, PIL and Pandas.
ER  - 

TY  - CONF
TI  - Deep Learning based Object Detection Algorithm for the Detection of Dental Diseases and Differential Treatments
T2  - 2022 IEEE 19th India Council International Conference (INDICON)
SP  - 1
EP  - 7
AU  - A. Thulaseedharan
AU  - L. P. P. S
PY  - 2022
KW  - Deep learning
KW  - Training
KW  - Neural networks
KW  - Object detection
KW  - Dentistry
KW  - Planning
KW  - Object recognition
KW  - Darknet
KW  - LabelImg
KW  - panoramic X-rays
KW  - Roboflow
KW  - Yolo v5
DO  - 10.1109/INDICON56171.2022.10040109
JO  - 2022 IEEE 19th India Council International Conference (INDICON)
IS  - 
SN  - 2325-9418
VO  - 
VL  - 
JA  - 2022 IEEE 19th India Council International Conference (INDICON)
Y1  - 24-26 Nov. 2022
AB  - With a wide range of applications in cosmetic dentistry treatments, and treatment planning, the use of Artificial Intelligence (AI) and Machine Learning is having a growing influence in the field of dentistry and is enhancing the growth of digital tools and technology. The surgical sector, automatic disease diagnosis, and recently established customized medicine are just a few of the disciplines that might benefit from AI support. Personalized medicine provides the inclination to diseases, diagnosis, and selection of the best treatment for a specific individual. In fields like image processing, deep learning has been able to match and improve human performance for exceedingly complicated tasks such as object detection models with classification, and prediction capabilities and for the identification of numerous dental diseases and their differential treatments. Many of these neural network applications face significant challenges due to the lack of labeled medical datasets, and oral disease datasets are no exception. This pilot study makes it possible to identify various dental diseases and the treatments for them by utilizing a dataset of 664 dental panoramic X-ray images which is considered a small number. These images have been used for training after being manually labeled for 9 separate classes. You Only Look Once (YOLO) version 5, a one-step search method primarily utilized for real-time object detection, is the deep neural network that was used in this study. Bounding boxes helped identify six differential treatments and three classes of dental diseases. Results show that this strategy was able to attain a Precision of 1.00, F1 score of 0.74, Recall of 0.83, and mAP of 72.4 percent by training with this smaller number of images, which shows tremendous potential for dentists and radiologists.
ER  - 

TY  - CONF
TI  - Dental Radiography Analysis and Diagnosis using YOLOv8
T2  - 2023 9th International Conference on Smart Computing and Communications (ICSCC)
SP  - 102
EP  - 107
AU  - J. George
AU  - T. S. Hemanth
AU  - J. Raju
AU  - J. G. Mattapallil
AU  - N. Naveen
PY  - 2023
KW  - Training
KW  - Deep learning
KW  - Computer vision
KW  - Computational modeling
KW  - Teeth
KW  - Dentistry
KW  - Diagnostic radiography
KW  - Panoramic Radiographs
KW  - Enhancement
KW  - GVF Snake
KW  - YOLO
KW  - Roboflow
KW  - Annotation
DO  - 10.1109/ICSCC59169.2023.10335023
JO  - 2023 9th International Conference on Smart Computing and Communications (ICSCC)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2023 9th International Conference on Smart Computing and Communications (ICSCC)
Y1  - 17-19 Aug. 2023
AB  - Panoramic dental radiography is a widely used diagnostic tool in dentistry that provides valuable information about a patient’s oral health. These two-dimensional images of the entire upper and lower jaw offer a comprehensive view of the oral cavity and allow for the diagnosis of various conditions, including tooth decay, periodontal diseases, and jaw abnormalities. The use of Gaussian and Laplacian pyramids for image enhancement is a common technique employed in this field. The GVF Snake technique, a computer vision approach, is utilized for dental radiograph analysis. It has proven effective in tasks such as tooth segmentation, root canal detection, and tooth movement analysis, improving the accuracy and efficiency of dental diagnosis and treatment planning. Manual annotation, model training, and deployment are facilitated by the computer vision platform Roboflow. The YOLOv8 training model, chosen for this research, has shown promising results with a precision of 82.36% in detecting and classifying dental diseases such as cavities, periodontal disease, and oral cancers. By training the model on a large dataset of dental radiographs, it can accurately identify different types of dental diseases, leading to early detection and more effective treatment. Overall, the integration of deep learning algorithms, image enhancement techniques, computer vision, and machine learning methods holds great potential in improving patient outcomes by enabling early detection, accurate diagnosis, and better management of dental conditions.
ER  - 

TY  - CONF
TI  - Advancements in Dental Diagnostics: YOLOv3-Powered Machine Learning for Automated Teeth Problem Detection
T2  - 2023 24th International Arab Conference on Information Technology (ACIT)
SP  - 1
EP  - 6
AU  - S. Odeh
AU  - A. Samara
AU  - N. Zreineh
AU  - S. Obeid
AU  - M. Ibrieghieth
AU  - M. Obaid
PY  - 2023
KW  - YOLO
KW  - Teeth
KW  - Machine learning
KW  - Medical services
KW  - Streaming media
KW  - Dentistry
KW  - Planning
DO  - 10.1109/ACIT58888.2023.10453865
JO  - 2023 24th International Arab Conference on Information Technology (ACIT)
IS  - 
SN  - 2831-4948
VO  - 
VL  - 
JA  - 2023 24th International Arab Conference on Information Technology (ACIT)
Y1  - 6-8 Dec. 2023
AB  - This paper presents a rigorous investigation into the application of state-of-the-art machine learning techniques for the automated detection of dental issues, utilizing the YOLOv3 Algorithm, a cutting-edge one-stage object detection method. The study encompasses the meticulous annotation and utilization of a carefully curated dataset featuring 126 panoramic X-ray images, illustrating a diverse range of dental conditions. Among these conditions, the primary emphasis is placed on the precise detection of six specific dental problems. Employing advanced computer vision methodologies, the model demonstrates exceptional accuracy in the identification and precise localization of these targeted dental issues. The implications of these findings are profound for the field of dental healthcare, as the automated detection of dental problems holds the potential to significantly enhance the diagnostic and treatment planning capabilities of dental professionals. The results presented in this research represent a notable stride in the ongoing evolution of machine learning and underscore its capacity to revolutionize the landscape of dental diagnostics, ultimately contributing to the advancement of oral health management and patient care.
ER  - 

TY  - CONF
TI  - Learning Orthodontic Cephalometry through Augmented Reality: A Conceptual Machine Learning Validation Approach
T2  - 2018 International Conference on Electrical Engineering and Informatics (ICELTICs)
SP  - 133
EP  - 138
AU  - G. K. Lakshmana Rao
AU  - N. Mokhtar
AU  - Y. H. P. Iskandar
AU  - A. Channarayapatna Srinivasa
PY  - 2018
KW  - Three-dimensional displays
KW  - Two dimensional displays
KW  - Machine learning
KW  - Solid modeling
KW  - Training
KW  - Software
KW  - Dentistry
KW  - orthodontic cephalometry
KW  - 3Dimaging
KW  - smart learning
KW  - augmented reality
KW  - machine learning
DO  - 10.1109/ICELTICS.2018.8548939
JO  - 2018 International Conference on Electrical Engineering and Informatics (ICELTICs)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2018 International Conference on Electrical Engineering and Informatics (ICELTICs)
Y1  - 19-20 Sept. 2018
AB  - The orthodontic cephalometry which forms a quintessential radiographic examination provides a valuable diagnostic resource for everyday orthodontic diagnosis and treatment planning. The method of analyzing the lateral cephalometric radiograph (LCR) has been found to lack effective methods of landmark identification and objective validation. This drawback, with the use of augmented reality (AR) for 3D visualization and machine learning for objective validation, can be effectively incorporated into the learning of cephalometrics. The two technologies together can produce a learning platform by reducing subjective errors and its implications on treatment planning in addition to effectively eliminating dissonance in learning.
ER  - 

TY  - CONF
TI  - Detection of typical Pathologies and Differential Treatments in Dental Panoramic X-Rays based on Deep Convolutional Neural Network
T2  - 2023 International Conference on Control, Communication and Computing (ICCC)
SP  - 1
EP  - 6
AU  - A. Thulaseedharan
AU  - L. P. P S
PY  - 2023
KW  - Deep learning
KW  - Training
KW  - Training data
KW  - Object detection
KW  - Dentistry
KW  - Object recognition
KW  - Task analysis
KW  - Darknet
KW  - LabelImg
KW  - panoramic X-rays
KW  - Roboflow
KW  - YOLO v6
DO  - 10.1109/ICCC57789.2023.10165614
JO  - 2023 International Conference on Control, Communication and Computing (ICCC)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2023 International Conference on Control, Communication and Computing (ICCC)
Y1  - 19-21 May 2023
AB  - Artificial Intelligence (AI) is gaining traction in medical imaging. There are a plethora of potential applications, covering every stage of the medical imaging life cycle from image creation to diagnosis to outcome prognosis. The use of Artificial Intelligence (AI) and Machine Learning is having a rising influence in the field of dentistry and is improving the growth of digital tools and technology, with a wide range of applications in cosmetic dental treatments and treatment planning. Deep learning has been able to match and improve human performance in fields such as image processing for extremely complex tasks such as object detection models with classification and prediction capabilities, as well as the identification of numerous dental diseases and their differential treatments. The lack of sufficiently large, curated, and representative training data with expert labeling (eg, annotations) is one of the main barriers to the development and clinical application of AI algorithms. This pilot study used a dataset of 664 dental panoramic X-ray images to build a model that can detect dental diseases and the differential treatments present on a full dental X-ray. After being manually labeled for 9 different classes, these images were used for training. The deep neural network used in this study is You Only Look Once (YOLO) version 6, a one-step search method primarily used for real-time object detection. Three classes of dental diseases and six classes of differential treatments were identified with the aid of bounding boxes. Results show that this strategy was able to attain a mean average precision (mAP) of 70.76% by training with this smaller number of images, which shows tremendous potential for dentists and radiologists.
ER  - 

TY  - CONF
TI  - Anatomical Landmarks Annotation on 2D Lateral Cephalograms with Channel Attention
T2  - 2022 22nd IEEE International Symposium on Cluster, Cloud and Internet Computing (CCGrid)
SP  - 952
EP  - 957
AU  - D. Du
AU  - T. Ren
AU  - C. Chen
AU  - Y. Jiang
AU  - G. Song
AU  - Q. Li
AU  - J. Niu
PY  - 2022
KW  - Training
KW  - Location awareness
KW  - Deep learning
KW  - Databases
KW  - Collaboration
KW  - Manuals
KW  - Feature extraction
KW  - Deep learning
KW  - landmark identification
KW  - attention mechanism
KW  - 2D X-ray cephalometric analysis
KW  - smart detection
DO  - 10.1109/CCGrid54584.2022.00116
JO  - 2022 22nd IEEE International Symposium on Cluster, Cloud and Internet Computing (CCGrid)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2022 22nd IEEE International Symposium on Cluster, Cloud and Internet Computing (CCGrid)
Y1  - 16-19 May 2022
AB  - Cephalometric tracing is widely used in orthodontic diagnosis and treatment planning. Since manual landmark lo-calization suffers from severe inter-observer and intra-observer inconsistency, a large number of efforts have been made by researchers to develop automatic localization methods. However, most of the existing methods are developed based on rules which sample uniformly from origin images rather than with the highest density in a focal point and ignore intermediate layers' results in their networks or their outputs' channels. To address the issue, this paper proposes a deep learning model based on multi-scale and multi-channel attention to identify landmarks. The channel attention network is first trained by multi-scale image patches cropped from 100 Cephalograms, and then enhanced by cross-layer connections to extract high-level features, finally involved in the collaboration with a three-layer MLP module to accurately locate coordinates. We conduct extensive evaluation on a real cephalometric X-ray data-set and a Non-public dataset, both achieve promising performance improvements especially in terms of high-precision detection.
ER  - 

TY  - CONF
TI  - Development of a software complex for the diagnosis of dentoalveolar anomalies using neural networks
T2  - 2021 International Conference on Information Technology and Nanotechnology (ITNT)
SP  - 1
EP  - 4
AU  - A. Kolsanov
AU  - N. Popov
AU  - I. Aiupova
AU  - K. Dobratulin
AU  - A. Gaidel
PY  - 2021
KW  - Software algorithms
KW  - Neural networks
KW  - Computer architecture
KW  - Software
KW  - Planning
KW  - Decoding
KW  - Convolutional neural networks
KW  - neural networks
KW  - computer vision
KW  - cephalometric analysis
KW  - teleradiography
KW  - orthodontics
DO  - 10.1109/ITNT52450.2021.9649289
JO  - 2021 International Conference on Information Technology and Nanotechnology (ITNT)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2021 International Conference on Information Technology and Nanotechnology (ITNT)
Y1  - 20-24 Sept. 2021
AB  - This article describes the goals and objectives of developing a software complex for planning the treatment of dentoalveolar anomalies, the architecture of the software complex as interacting components for treatment planning, as well as the principle of using algorithms using convolutional neural networks within the software complex for a component that solves the problem of decoding a teleradiographic image.
ER  - 

TY  - CONF
TI  - Processing and Segmentation of Human Teeth from 2D Images using Weakly Supervised Learning
T2  - 2023 World Symposium on Digital Intelligence for Systems and Machines (DISA)
SP  - 133
EP  - 139
AU  - T. Kunzo
AU  - V. Kocur
AU  - L. Gajdošech
AU  - M. Madaras
PY  - 2023
KW  - Deep learning
KW  - Image segmentation
KW  - Annotations
KW  - Supervised learning
KW  - Teeth
KW  - Manuals
KW  - Feature extraction
KW  - image processing
KW  - deep learning
KW  - segmentation
KW  - weakly supervised learning
DO  - 10.1109/DISA59116.2023.10308924
JO  - 2023 World Symposium on Digital Intelligence for Systems and Machines (DISA)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2023 World Symposium on Digital Intelligence for Systems and Machines (DISA)
Y1  - 21-22 Sept. 2023
AB  - Teeth segmentation is an essential task in dental image analysis for accurate diagnosis and treatment planning. While supervised deep learning methods can be utilized for teeth segmentation, they often require extensive manual annotation of segmentation masks, which is time-consuming and costly. In this research, we propose a weakly supervised approach for teeth segmentation that reduces the need for manual annotation. Our method utilizes the output heatmaps and intermediate feature maps from a keypoint detection network to guide the segmentation process. We introduce the TriDental dataset, consisting of 3000 oral cavity images annotated with teeth keypoints, to train a teeth keypoint detection network. We combine feature maps from different layers of the keypoint detection network, enabling accurate teeth segmentation without explicit segmentation annotations. The detected keypoints are also used for further refinement of the segmentation masks. Experimental results on the TriDental dataset demonstrate the superiority of our approach in terms of accuracy and robustness compared to state-of-the-art segmentation methods. Our method offers a cost-effective and efficient solution for teeth segmentation in real-world dental applications, eliminating the need for extensive manual annotation efforts.
ER  - 

TY  - JOUR
TI  - Deep Multi-Scale Mesh Feature Learning for Automated Labeling of Raw Dental Surfaces From 3D Intraoral Scanners
T2  - IEEE Transactions on Medical Imaging
SP  - 2440
EP  - 2450
AU  - C. Lian
AU  - L. Wang
AU  - T. -H. Wu
AU  - F. Wang
AU  - P. -T. Yap
AU  - C. -C. Ko
AU  - D. Shen
PY  - 2020
KW  - Teeth
KW  - Dentistry
KW  - Three-dimensional displays
KW  - Labeling
KW  - Shape
KW  - Feature extraction
KW  - Surface morphology
KW  - 3D shape segmentation
KW  - geometric deep learning
KW  - automated tooth labeling
KW  - orthodontic treatment planning
KW  - 3D intraoral scanners
DO  - 10.1109/TMI.2020.2971730
JO  - IEEE Transactions on Medical Imaging
IS  - 7
SN  - 1558-254X
VO  - 39
VL  - 39
JA  - IEEE Transactions on Medical Imaging
Y1  - July 2020
AB  - Precisely labeling teeth on digitalized 3D dental surface models is the precondition for tooth position rearrangements in orthodontic treatment planning. However, it is a challenging task primarily due to the abnormal and varying appearance of patients' teeth. The emerging utilization of intraoral scanners (IOSs) in clinics further increases the difficulty in automated tooth labeling, as the raw surfaces acquired by IOS are typically low-quality at gingival and deep intraoral regions. In recent years, some pioneering end-to-end methods (e.g., PointNet) have been proposed in the communities of computer vision and graphics to consume directly raw surface for 3D shape segmentation. Although these methods are potentially applicable to our task, most of them fail to capture fine-grained local geometric context that is critical to the identification of small teeth with varying shapes and appearances. In this paper, we propose an end-to-end deep-learning method, called MeshSegNet, for automated tooth labeling on raw dental surfaces. Using multiple raw surface attributes as inputs, MeshSegNet integrates a series of graph-constrained learning modules along its forward path to hierarchically extract multi-scale local contextual features. Then, a dense fusion strategy is applied to combine local-to-global geometric features for the learning of higher-level features for mesh cell annotation. The predictions produced by our MeshSegNet are further post-processed by a graph-cut refinement step for final segmentation. We evaluated MeshSegNet using a real-patient dataset consisting of raw maxillary surfaces acquired by 3D IOS. Experimental results, performed 5-fold cross-validation, demonstrate that MeshSegNet significantly outperforms state-of-the-art deep learning methods for 3D shape segmentation.
ER  - 

TY  - JOUR
TI  - Automatic Detection of Tooth-Gingiva Trim Lines on Dental Surfaces
T2  - IEEE Transactions on Medical Imaging
SP  - 3194
EP  - 3204
AU  - G. Chen
AU  - J. Qin
AU  - B. B. Amor
AU  - W. Zhou
AU  - H. Dai
AU  - T. Zhou
AU  - H. Huang
AU  - L. Shao
PY  - 2023
KW  - Dentistry
KW  - Teeth
KW  - Deep learning
KW  - Surface treatment
KW  - Feature extraction
KW  - Three-dimensional displays
KW  - Proposals
KW  - Dental surface
KW  - tooth-gingiva trim line
KW  - geometric deep learning
KW  - LDDMM
KW  - template fitting
DO  - 10.1109/TMI.2023.3263161
JO  - IEEE Transactions on Medical Imaging
IS  - 11
SN  - 1558-254X
VO  - 42
VL  - 42
JA  - IEEE Transactions on Medical Imaging
Y1  - Nov. 2023
AB  - Detecting the tooth-gingiva trim line from a dental surface plays a critical role in dental treatment planning and aligner 3D printing. Existing methods treat this task as a segmentation problem, which is resolved with geometric deep learning based mesh segmentation techniques. However, these methods can only provide indirect results (i.e., segmented teeth) and suffer from unsatisfactory accuracy due to the incapability of making full use of high-resolution dental surfaces. To this end, we propose a two-stage geometric deep learning framework for automatically detecting tooth-gingiva trim lines from dental surfaces. Our framework consists of a trim line proposal network (TLP-Net) for predicting an initial trim line from the low-resolution dental surface as well as a trim line refinement network (TLR-Net) for refining the initial trim line with the information from the high-resolution dental surface. Specifically, our TLP-Net predicts the initial trim line by fusing the multi-scale features from a U-Net with a proposed residual multi-scale attention fusion module. Moreover, we propose feature bridge modules and a trim line loss to further improve the accuracy. The resulting trim line is then fed to our TLR-Net, which is a deep-based LDDMM model with the high-resolution dental surface as input. In addition, dense connections are incorporated into TLR-Net for improved performance. Our framework provides an automatic solution to trim line detection by making full use of raw high-resolution dental surfaces. Extensive experiments on a clinical dental surface dataset demonstrate that our TLP-Net and TLR-Net are superior trim line detection methods and outperform cutting-edge methods in both qualitative and quantitative evaluations.
ER  - 

TY  - JOUR
TI  - Automatic Segmentation of Individual Tooth in Dental CBCT Images From Tooth Surface Map by a Multi-Task FCN
T2  - IEEE Access
SP  - 97296
EP  - 97309
AU  - Y. Chen
AU  - H. Du
AU  - Z. Yun
AU  - S. Yang
AU  - Z. Dai
AU  - L. Zhong
AU  - Q. Feng
AU  - W. Yang
PY  - 2020
KW  - Teeth
KW  - Image segmentation
KW  - Dentistry
KW  - Level set
KW  - Three-dimensional displays
KW  - Decoding
KW  - Bones
KW  - Individual tooth segmentation
KW  - dental CBCT
KW  - deep learning
KW  - marker-controlled watershed transform
DO  - 10.1109/ACCESS.2020.2991799
JO  - IEEE Access
IS  - 
SN  - 2169-3536
VO  - 8
VL  - 8
JA  - IEEE Access
Y1  - 2020
AB  - Accurate and automatic segmentation of individual tooth is critical for computer-aided analysis towards clinical decision support and treatment planning. Three-dimensional reconstruction of individual tooth after the segmentation also plays an important role in simulation in digital orthodontics. However, it is difficult to automatically segment individual tooth in cone beam computed tomography (CBCT) images due to the blurring boundaries of neighboring teeth and the similar intensities between teeth and mandible bone. In this work, we propose the use of a multi-task 3D fully convolutional network (FCN) and marker-controlled watershed transform (MWT) to segment individual tooth. The multi-task FCN learns to simultaneously predict the probability of tooth region and the probability of tooth surface. Through the combination of the tooth probability gradient map and the surface probability map as the input image, MWT is used to automatically separate and segment individual tooth. Twenty-five dental CBCT scans are used in the study. The average Dice similarity coefficient, Jaccard index, and relative volume difference are 0.936 (±0.012), 0.881 (±0.019), and 0.072 (±0.027), respectively, and the average symmetric surface distance is 0.363 (±0.145) mm for our method. The experimental results demonstrate that the multi-task 3D FCN combined with MWT can segment individual tooth of various types in dental CBCT images.
ER  - 

TY  - CONF
TI  - Self-Supervised Learning with Masked Autoencoders for Teeth Segmentation from Intra-oral 3D Scans
T2  - 2024 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)
SP  - 7805
EP  - 7815
AU  - A. Almalki
AU  - L. J. Latecki
PY  - 2024
KW  - Training
KW  - Three-dimensional displays
KW  - Transfer learning
KW  - Teeth
KW  - Self-supervised learning
KW  - Transformers
KW  - Loss measurement
KW  - Applications
KW  - Biomedical / healthcare / medicine
DO  - 10.1109/WACV57701.2024.00764
JO  - 2024 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)
IS  - 
SN  - 2642-9381
VO  - 
VL  - 
JA  - 2024 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)
Y1  - 3-8 Jan. 2024
AB  - In modern dentistry, teeth localization, segmentation, and labeling from intra-oral 3D scans are crucial for improving dental diagnostics, treatment planning, and population-based studies on oral health. However, creating automated algorithms for teeth analysis is a challenging task due to the limited availability of accessible data for training, particularly from the point of view of deep learning. This study extends the self-supervised learning framework of the mesh masked autoencoder (MeshMAE) transformer. While the MeshMAE loss measures the quality of reconstructed masked mesh triangles, the loss of the proposed DentalMAE evaluates the predicted deep embeddings of masked mesh triangles. This yields a better generalization ability on a very limited number of 3D dental scans, as documented by our results on teeth segmentation of intra-oral scans. Our results show that masking-based unsupervised learning methods may, for the first time, provide convincing transfer learning improvements on 3D intra-oral scans, increasing the overall accuracy over both MeshMAE and prior self-supervised pre-training.
ER  - 

TY  - JOUR
TI  - Dental Impression Tray Selection From Maxillary Arch Images Using Multi-Feature Fusion and Ensemble Classifier
T2  - IEEE Access
SP  - 30573
EP  - 30586
AU  - M. A. Hasan
AU  - N. A. Abdullah
AU  - M. M. Rahman
AU  - M. Y. I. B. Idris
AU  - O. F. Tawfiq
PY  - 2021
KW  - Dentistry
KW  - Feature extraction
KW  - Image color analysis
KW  - Shape
KW  - Medical diagnostic imaging
KW  - Image recognition
KW  - Computer vision
KW  - Dental impression tray
KW  - dental arch image
KW  - automation in dentistry
KW  - computer vision
KW  - multi-feature fusion
KW  - ensemble classifier
DO  - 10.1109/ACCESS.2021.3059785
JO  - IEEE Access
IS  - 
SN  - 2169-3536
VO  - 9
VL  - 9
JA  - IEEE Access
Y1  - 2021
AB  - Dental impression tray is frequently used in dentistry to record the patient's oral structure for clinical oral diagnosis and treatment planning. Manual procedure of taking impressions is costly, time-consuming, and additionally, no research has been done on selecting dental impression tray from dental arch images using computer vision in real-life scenarios. In this spirit, an intelligent model is proposed based on computer vision and machine learning to select appropriate dental impression trays from maxillary arch images. A dataset of 52 patients' maxillary arch images have been acquired and various sets of features such as colors, textures, and shapes of the images were extracted to better characterize the maxillary arch images. Considering the importance of the features in describing the maxillary arch object and to improve the classification performance, a method based on multi-feature fusion with ensemble classifier is proposed. Besides, the performance of a deep learning based multilayer perceptron neural network is also investigated. The proposed multi-feature fusion with ensemble classifier attained 92.31% precision, 91.75% recall, 91.75% accuracy, respectively, on the dataset, which clearly establishes the feasibility of the proposed model. An illustration of a real-life application of the proposed model is also provided.
ER  - 

TY  - CONF
TI  - Deep Learning-Based Analysis of Liquid Biopsies for Uterus Cancer Biomarker Discovery
T2  - 2023 9th International Conference on Smart Structures and Systems (ICSSS)
SP  - 1
EP  - 6
AU  - S. Lalitha
AU  - M. I. Haque
AU  - V. Sujay
AU  - M. Shenbagapriya
AU  - G. G
AU  - S. Salyan
PY  - 2023
KW  - Deep learning
KW  - Liquids
KW  - Surveillance
KW  - Biomarkers
KW  - Cancer detection
KW  - Turning
KW  - Cancer
KW  - Liquid Biopsies
KW  - Uterine Cancer
KW  - Deep Learning
KW  - Neural Network
KW  - Disease Biomarkers
DO  - 10.1109/ICSSS58085.2023.10407561
JO  - 2023 9th International Conference on Smart Structures and Systems (ICSSS)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2023 9th International Conference on Smart Structures and Systems (ICSSS)
Y1  - 23-24 Nov. 2023
AB  - In regard to the critical nature of early cancer detection, including uterine cancer, non-invasive liquid biopsies are demonstrating their utility. The present study presents an innovative deep-learning approach specifically designed for the examination of liquid specimens, aiming to detect potential biomarkers associated with uterine cancer. By employing advanced neural network architectures and sizable genomic datasets, the methodology discerns particular molecular markers that are correlated with uterine cancer. The implementation of personalized treatment plans and early intervention strategies to enhance patient outcomes is a feasible prospect rendered feasible by the results of this study. This innovative methodology signifies a turning point in the continuous effort to combat uterine cancer and exemplifies the potential transformative effects that deep learning techniques could have on cancer prognosis and precision medicine.
ER  - 

TY  - CONF
TI  - Multi-Scale Bidirectional Enhancement Network for 3d Dental Model Segmentation
T2  - 2022 IEEE 19th International Symposium on Biomedical Imaging (ISBI)
SP  - 1
EP  - 5
AU  - Z. Li
AU  - T. Liu
AU  - J. Wang
AU  - C. Zhang
AU  - X. Jia
PY  - 2022
KW  - Deep learning
KW  - Solid modeling
KW  - Analytical models
KW  - Image segmentation
KW  - Three-dimensional displays
KW  - Shape
KW  - Neural networks
KW  - Dental model segmentation
KW  - 3D deep learning
KW  - convolution neural network
KW  - orthodontic treatment planning
DO  - 10.1109/ISBI52829.2022.9761556
JO  - 2022 IEEE 19th International Symposium on Biomedical Imaging (ISBI)
IS  - 
SN  - 1945-8452
VO  - 
VL  - 
JA  - 2022 IEEE 19th International Symposium on Biomedical Imaging (ISBI)
Y1  - 28-31 March 2022
AB  - Given the importance of 3D sensors, a fine-grained analysis on 3D dental model is an important task in computer-aided orthodontic treatment planning. Particularly, the real 3D dental model can intuitively show the shape and morphology of the tooth, but due to the irregularity of the 3D tooth data, it poses a challenge for accurate tooth segmentation. In this work, with the mesh data as input, we propose an end-to-end deep neural network, called MBESegNet, for accurate tooth segmentation on 3D dental models. On the one hand, to reduce the ambiguity of the mesh feature representation near the tooth boundary, MBESegNet learns the local context by enhancing the geometric and semantic features with a bidirectional and symmetric structure. On the other hand, MBESeg-Net hierarchically captures the multi-scale contextual features from different scales and represent the feature map following a coarse-to-fine feature fusion strategy for accurate tooth segmentation. The experimental results demonstrate that our approach achieves competitive performance against state-of-the-art 3D shape segmentation methods.
ER  - 

TY  - CONF
TI  - Early Detection of Lung Cancer Using Deep Learning-Based Analysis of CT Scans
T2  - 2023 9th International Conference on Smart Structures and Systems (ICSSS)
SP  - 1
EP  - 6
AU  - D. Muthukumaran
AU  - R. Ahmad
AU  - S. Suneel
AU  - K. L. Kumar
AU  - S. Mujoo
AU  - S. N. Taqui
PY  - 2023
KW  - Deep learning
KW  - Computed tomography
KW  - Semantic segmentation
KW  - Lung cancer
KW  - Computer architecture
KW  - Prognostics and health management
KW  - Medical diagnostic imaging
KW  - Medical image analysis
KW  - Lung cancer
KW  - Early detection
KW  - Deep learning
KW  - UNET
KW  - LeNet
DO  - 10.1109/ICSSS58085.2023.10407997
JO  - 2023 9th International Conference on Smart Structures and Systems (ICSSS)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2023 9th International Conference on Smart Structures and Systems (ICSSS)
Y1  - 23-24 Nov. 2023
AB  - The advanced stage at which most occurrences of lung cancer (LC) are detected results in a dismal prognosis and few available therapeutic options for the disease. The ability to diagnose lung cancer at an early stage is an important clinical and scientific emphasis since it can greatly improve patient outcomes. Recent advances in deep learning have made it possible to use these methods effectively on medical images, which might improve the speed and precision with which lung cancer is diagnosed. Using deep learning to analyze computed tomography (CT) scans, this study introduces a unique method for the early diagnosis of lung cancer. The proposed method leverages a combination of two deep neural network architectures, UNET and LeNet, to achieve robust and accurate lung cancer detection. The UNET architecture is employed for semantic segmentation of lung regions from CT scans, allowing for precise localization and isolation of potential cancerous lesions. Subsequently, the LeNet architecture is applied to classify the segmented regions as either benign or malignant. This two-stage approach enables the model to identify lung cancer with high accuracy while minimizing false positives. Based on the results of this study, combining UNET and LeNet for CT scan analysis may result in an accuracy of 97.89%, providing doctors with a useful tool to enhance patient outcomes through prompt intervention.
ER  - 

TY  - CONF
TI  - Comparative Analysis of ResNet101, InceptionV3, and InceptionResnetV2 Architectures for Cervical Vertebrae Maturation Stage Classification
T2  - 2023 International Conference on Electrical Engineering and Informatics (ICEEI)
SP  - 1
EP  - 5
AU  - G. A. Kresnadhi
AU  - M. F. Nurrajab
AU  - A. Z. Ilmi
AU  - M. A. Septiawan
AU  - A. Handayani
AU  - W. Adiprawita
AU  - I. Anshori
PY  - 2023
KW  - Electrical engineering
KW  - Deep learning
KW  - Visualization
KW  - Crops
KW  - Bones
KW  - Planning
KW  - Convolutional neural networks
KW  - Resnet101
KW  - InceptionV3
KW  - InceptionResnetV2
KW  - Cervical Vertebrae Maturity (CVM)
DO  - 10.1109/ICEEI59426.2023.10346871
JO  - 2023 International Conference on Electrical Engineering and Informatics (ICEEI)
IS  - 
SN  - 2155-6830
VO  - 
VL  - 
JA  - 2023 International Conference on Electrical Engineering and Informatics (ICEEI)
Y1  - 10-11 Oct. 2023
AB  - The classification of cervical vertebrae maturity (CVM) plays a crucial role in orthodontic diagnosis and treatment planning. This study aims to evaluate the performances of bone maturity classification using three convolutional neural network architectures. The dataset used in this study utilizes the CVM-900 dataset which contains labeled cervical vertebrae x-ray images in 6 levels of bone maturation. Preprocessing was conducted by ROI cropping which results in three datasets: Crop C2-C4, Crop C2-C6, and uncrop. Then, to decrease the possibility of overfitting, the datasets are augmented with random translation and rotation. This work compares three pre-trained networks: ResNet-101, InceptionResNetV2, and InceptionV3. Each network has unique characteristics to improve performance in deep learning. Visual explanations of CVM stage classification from each model are conducted through Grad-CAM which leverages the gradient information to the target classes. We found that InceptionResNetV2 yields the highest accuracy across models and ROIs. It is shown that ROI affects model's performance. However, due to overfitting and the inability of our model to infer multiscale features, the increase in accuracy is not as significant.
ER  - 

TY  - JOUR
TI  - CephXNet: A Deep Convolutional Squeeze-and-Excitation Model for Landmark Prediction on Lateral Cephalograms
T2  - IEEE Access
SP  - 90780
EP  - 90800
AU  - R. Neeraja
AU  - L. Jani Anbarasi
PY  - 2023
KW  - X-ray imaging
KW  - Convolutional neural networks
KW  - Predictive models
KW  - Computer architecture
KW  - Surgery
KW  - Planning
KW  - Feature extraction
KW  - Artificial neural networks
KW  - Deep learning
KW  - Classification algorithms
KW  - Artificial deep neural networks
KW  - squeeze-and-excitation block
KW  - cephalometric landmark classification
KW  - landmark prediction
KW  - X-ray images
DO  - 10.1109/ACCESS.2023.3307636
JO  - IEEE Access
IS  - 
SN  - 2169-3536
VO  - 11
VL  - 11
JA  - IEEE Access
Y1  - 2023
AB  - Cephalometric landmark identification is a crucial and significant procedure that is generally used for orthodontic treatment planning and diagnosis. Computer-aided fully automated solutions can assist orthodontists and orthognathic surgeons’ to precisely identify the landmarks from cephalograms more efficiently. Most of the existing research studies deployed Convolutional Neural Network models, transfer learning methods, and pre-trained architectures to predict the XY coordinates of landmarks from cephalometric radiographs. Deep learning architectures have achieved good results in accurately predicting landmarks compared to machine learning methodologies. In this paper, a custom CNN model integrated with Squeeze-and-Excitation (SEB) attention block named CephXNet architecture is proposed to automatically classify and predicts the XY coordinates of 19 landmarks from lateral cephalograms. The SEB block, which can adaptively refine information from various feature channels of X-ray images models the interdependence between the channels to enhance the discriminative features and suppress noise. The Squeeze-and-Excitation block incorporated with multiple Convolution and Max pooling layers enhances independent channel feature learning and thereby improves the representational power of the proposed CephXNet architecture. The proposed framework obtained an accuracy of 97.72% for 19 landmark classifications and has achieved 88.06% and 78.72% of Successful Detection Rate (SDR) in clinically accepted 2mm precision range for test1 and test2 datasets provided in the 2015 International Symposium on Biomedical Imaging (ISBI) grand challenge for dental X-ray analysis conducted by IEEE. Furthermore, the proposed CephXNet is also tested with private clinical dataset comprised of 100 cephalograms collected from Solanki Dental Care Clinic in Sharjah, United Arab Emirates. The proposed CephXNet model obtained a classification accuracy of 90.08% and an average SDR of 73.94% in the 2mm precision range. The experimental outcomes show proposed CephXNet model is efficient and has great potential to deploy in clinical practice.
ER  - 

TY  - CONF
TI  - Enhanced Masked Image Modeling for Analysis of Dental Panoramic Radiographs
T2  - 2023 IEEE 20th International Symposium on Biomedical Imaging (ISBI)
SP  - 1
EP  - 5
AU  - A. Almalki
AU  - L. J. Latecki
PY  - 2023
KW  - Radiography
KW  - Training
KW  - Image segmentation
KW  - Visualization
KW  - X-rays
KW  - Self-supervised learning
KW  - Teeth
KW  - Self-distillation
KW  - Self-supervised learning
KW  - Masked image modeling
KW  - Object detection
KW  - Instance segmentation
DO  - 10.1109/ISBI53787.2023.10230656
JO  - 2023 IEEE 20th International Symposium on Biomedical Imaging (ISBI)
IS  - 
SN  - 1945-8452
VO  - 
VL  - 
JA  - 2023 IEEE 20th International Symposium on Biomedical Imaging (ISBI)
Y1  - 18-21 April 2023
AB  - The computer-assisted radiologic informative report has received increasing research attention to facilitate diagnosis and treatment planning for dental care providers. However, manual interpretation of dental images is limited, expensive, and time-consuming. Another barrier in dental imaging is the limited number of available images for training, which is a challenge in the era of deep learning. This study proposes a novel self-distillation (SD) enhanced self-supervised learning on top of the masked image modeling (SimMIM) Transformer, called SD-SimMIM, to improve the outcome with a limited number of dental radiographs. In addition to the prediction loss on masked patches, SD-SimMIM computes the self-distillation loss on the visible patches. We apply SD-SimMIM on dental panoramic X-rays for teeth numbering, detection of dental restorations and orthodontic appliances, and instance segmentation tasks. Our results show that SD-SimMIM outperforms other self-supervised learning methods. Furthermore, we augment and improve the annotation of an existing dataset of panoramic X-rays.
ER  - 

TY  - CONF
TI  - An automatic cephalometric landmark detection method based on heatmap regression and Monte Carlo dropout
T2  - 2023 45th Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC)
SP  - 1
EP  - 4
AU  - J. Chen
AU  - H. Che
AU  - J. Sun
AU  - Y. Rao
AU  - J. Wu
PY  - 2023
KW  - Heating systems
KW  - Uncertainty
KW  - Monte Carlo methods
KW  - Medical services
KW  - Robustness
KW  - Hardware
KW  - Planning
DO  - 10.1109/EMBC40787.2023.10341102
JO  - 2023 45th Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC)
IS  - 
SN  - 2694-0604
VO  - 
VL  - 
JA  - 2023 45th Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC)
Y1  - 24-27 July 2023
AB  - Cephalometric analysis plays an important role in orthodontic diagnosis and treatment planning. It depends on the detection of multiple landmarks, while the process is time-consuming and tedious. Although some deep learning-based automatic landmark detection algorithms have achieved excellent performance, most of them adopt multi-stage models increasing the complexity and detection time. Meanwhile, few studies focused on the uncertainty of detection results, thereby ignoring its significant clinical value. In this paper, we propose a novel approach based on heatmap regression for landmark detection, which can achieve competitive accuracy and good robustness with only one step. Furthermore, by applying Monte Carlo dropout to a U-shaped convolutional neural network, we can obtain not only the coordinate of each landmark but also the corresponding simple uncertainty, so that doctors can pay more attention to those landmarks with higher uncertainty. The evaluation results showed the mean radial error is 1.39±1.06mm and the average successful detection rate is 79.65%, 97.22% within 2mm, 4mm for the IEEE ISBI2015 Test Dataset 1, the indicators for the IEEE ISBI2015 Test Dataset 2 are 1.33±0.93mm, 80.05% and 97.53%, respectively. Our method has the potential to become an assistant tool in clinical practice. Automatic and accurate detection with uncertainty analysis is expected to help guide the doctor’s judgment.
ER  - 

TY  - JOUR
TI  - Deep-Learning-Based Segmentation of Individual Tooth and Bone With Periodontal Ligament Interface Details for Simulation Purposes
T2  - IEEE Access
SP  - 102460
EP  - 102470
AU  - P. Xu
AU  - T. Gholamalizadeh
AU  - F. Moshfeghifar
AU  - S. Darkner
AU  - K. Erleben
PY  - 2023
KW  - Bones
KW  - Image segmentation
KW  - Three-dimensional displays
KW  - Ligaments
KW  - Solid modeling
KW  - Watersheds
KW  - Pipelines
KW  - Finite element analysis
KW  - Human factors
KW  - Semantic segmentation
KW  - Cone-beam computed tomography
KW  - deep learning
KW  - finite element modeling
KW  - human jaws
KW  - instance segmentation
KW  - learning with limited data
KW  - semantic segmentation
KW  - transfer learning
DO  - 10.1109/ACCESS.2023.3317512
JO  - IEEE Access
IS  - 
SN  - 2169-3536
VO  - 11
VL  - 11
JA  - IEEE Access
Y1  - 2023
AB  - The process of constructing precise geometry of human jaws from cone beam computed tomography (CBCT) scans is crucial for building finite element models and treatment planning. Despite the success of deep learning techniques, they struggle to accurately identify delicate features such as thin structures and gaps between the tooth-bone interfaces where periodontal ligament resides, especially when trained on limited data. Therefore, segmented geometries obtained through automated methods still require extensive manual adjustment to achieve a smooth and organic 3D geometry that is suitable for simulations. In this work, we require the model to provide anatomically correct segmentation of teeth and bones which preserves the space for the periodontal ligament layers. To accomplish the task with few accurate labels, we pre-train a modified MultiPlanar UNet as the backbone model using inferior segmentations, i.e., tooth-bone segmentation with no space in the tooth-bone interfaces, and fine-tune the model with a dedicated loss function over accurate delineations that considers the space. We demonstrate that our approach can produce proper tooth-bone segmentations with gap interfaces that are fit for simulations when applied to human jaw CBCT scans. Furthermore, we propose a marker-based watershed segmentation applied on the MultiPlanar UNet probability map to separate individual tooth. This has advantages when the segmentation task is challenged by common artifacts caused by restorative materials or similar intensities in the teeth-teeth interfaces in occurrence of crowded teeth phenomenon. Code and segmentation results are available at https://github.com/diku-dk/AutoJawSegment.
ER  - 

TY  - CONF
TI  - AUTOMATIC LOCALIZATION OF LANDMARKS IN CEPHALOMETRIC IMAGES Via MODIFIED U-Net
T2  - 2019 10th International Conference on Computing, Communication and Networking Technologies (ICCCNT)
SP  - 1
EP  - 6
AU  - E. N. D. Goutham
AU  - S. Vasamsetti
AU  - P. V. V. Kishore
AU  - H. K. Sardana
PY  - 2019
KW  - deep neural networks
KW  - cephalometric landmarks
KW  - lateral cephalograms
KW  - X-ray images
KW  - convolution neural networks
DO  - 10.1109/ICCCNT45670.2019.8944411
JO  - 2019 10th International Conference on Computing, Communication and Networking Technologies (ICCCNT)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2019 10th International Conference on Computing, Communication and Networking Technologies (ICCCNT)
Y1  - 6-8 July 2019
AB  - Cephalometric analysis is basic assessment aid for orthodontics, oral & maxillofacial surgery and treatment planning. The identification of landmark locations on lateral cephalograms plays a critical role in the clinical analysis, automating this process could reduce possible human errors and time consumption. This work explores the automation of landmark detection process using deep learning framework. The modified U-Net model has been trained on seven landmarks and implemented to locate the same in test images. The proposed model has been evaluated with dice metrics which was observed to be approximately 88 percent for each landmark. The successful detection rate has been calculated and compared with two other prominent methods, comparable results were achieved which comes under clinically acceptable range. This work is in the early stages as not many deep learning methods explored in this particular domain, which demonstrates assurance for improvement in computer-aided treatment and surgery planning.
ER  - 

TY  - CONF
TI  - Exploring the Use of a Network Model in Drug Prescription Support for Dental Clinics
T2  - 2018 5th International Conference on Behavioral, Economic, and Socio-Cultural Computing (BESC)
SP  - 168
EP  - 172
AU  - W. P. Goh
AU  - X. Tao
AU  - J. Zhang
AU  - J. Yong
AU  - Y. Qin
AU  - E. Z. Goh
AU  - A. Hu
PY  - 2018
KW  - Drugs
KW  - Computational modeling
KW  - Dentistry
KW  - Medical diagnostic imaging
KW  - Feature extraction
KW  - Knowledge based systems
KW  - Predictive models
KW  - drug adverse interaction
KW  - clinical decision support
KW  - network model
KW  - drug prescription
DO  - 10.1109/BESC.2018.8697814
JO  - 2018 5th International Conference on Behavioral, Economic, and Socio-Cultural Computing (BESC)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2018 5th International Conference on Behavioral, Economic, and Socio-Cultural Computing (BESC)
Y1  - 12-14 Nov. 2018
AB  - With more patients taking multiple medications and the increasing digital availability of diagnostic data such as treatment notes and x-ray images, the importance of decision support systems to help dentists in their treatment planning cannot be over emphasised. Based on the hypothesis that a higher similarity ratio between drugs in a drug-pair indicates that the combination of the drug-pair has a higher chance of an adverse interaction, this paper describes an efficient approach in extracting feature vectors from the drugs in a drug-pair to compute the similarity ratio between them. The feature vectors are obtained through a network model where the information of the drugs are represented as nodes and the relationships between them represented as edges. Experimental evaluation of our model yielded a superior F score of 74%. The use of a network model will drive research efforts into more efficient data-mining algorithms for information retrieval, similarity search and machine learning. Since it is important to avoid drug allergies when prescribing drugs, our work when integrated within the clinical work-flow will reduce prescription errors thereby increasing health outcomes for patients.
ER  - 

TY  - CONF
TI  - Dental X-Ray Image Analysis for Diagnosis Utilized Convolutional Neural Network Using Real-Time Performance
T2  - 2023 3rd International Conference on Mobile Networks and Wireless Communications (ICMNWC)
SP  - 1
EP  - 6
AU  - M. Y. Arabi
AU  - G. M. Ramadan
AU  - R. A. Reddy
AU  - M. I. Habelalmateen
AU  - P. K
PY  - 2023
KW  - Wireless communication
KW  - Training
KW  - Image analysis
KW  - Dentistry
KW  - Convolutional neural networks
KW  - X-ray imaging
KW  - Testing
KW  - Convolutional Neural Network
KW  - Dental X-Ray Image
KW  - Histogram Equalization
KW  - ResNet and U-Net
DO  - 10.1109/ICMNWC60182.2023.10435896
JO  - 2023 3rd International Conference on Mobile Networks and Wireless Communications (ICMNWC)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2023 3rd International Conference on Mobile Networks and Wireless Communications (ICMNWC)
Y1  - 4-5 Dec. 2023
AB  - The diagnostic methods available to dentists for caries detection have multiplied in dental X-ray images. In the research, a classification system was designed using Convolutional Neural Network (CNN) analysis to obtain the best parameters for the system. CNNs can be trained to detect and classify dental conditions, such as cavities which can assist dentists in diagnosing and treatment planning. The large number of X-ray images allows dentists to make quicker decisions, reducing the time and risk of interpreting the X-rays. After testing three different image sizes, it was found that an image size of 224 × 224 pixels yielded the best testing results and graphs. This is because each pixel contains information about the image, and larger image sizes provide more detailed information. Therefore, over time, monitoring with CNNs can help dentists track the progress of ongoing treatments and interventions. To evaluate the effectiveness of these models, experiments were conducted on a manually annotated dataset known as Dental X-ray Images. The experimental results demonstrate that the CNN achieved an accuracy rate of 98.60%, surpassing other existing models such as ResNet, U-Net, and DenseNet.
ER  - 

TY  - JOUR
TI  - A Framework to Enhance the Experience of CBCT Data in Real-Time Using Immersive Virtual Reality: Impacting Dental Pre-Surgical Planning
T2  - IEEE Access
SP  - 45442
EP  - 45455
AU  - S. H. Bhat
AU  - K. S. Hareesha
AU  - A. T. Kamath
AU  - A. Kudva
AU  - R. Vineetha
AU  - A. Nair
PY  - 2024
KW  - Dentistry
KW  - Data visualization
KW  - Surgery
KW  - Real-time systems
KW  - Planning
KW  - Three-dimensional displays
KW  - Rendering (computer graphics)
KW  - Computed tomography
KW  - Virtual reality
KW  - Immersive experience
KW  - Cone-beam computed tomography
KW  - virtual reality
KW  - volume rendering
KW  - GPU-based ray marching technique
KW  - immersive visualization
KW  - dental surgical planning
DO  - 10.1109/ACCESS.2024.3375770
JO  - IEEE Access
IS  - 
SN  - 2169-3536
VO  - 12
VL  - 12
JA  - IEEE Access
Y1  - 2024
AB  - Dental surgery has undergone a significant evolution with the advent of cone-beam computed tomography (CBCT), offering intricate 3D imagery vital for surgical planning, interventions, and diagnostics. Nonetheless, the comprehension of the extensive and intricate CBCT data remains a persistent challenge. To address this, virtual reality (VR) has emerged as a promising solution, empowering dental professionals to engage with CBCT data in real-time. This study introduces a VR framework meticulously designed for interactive and immersive visualization of CBCT data, enhancing the understanding of complex dental structures and pre-operative planning in dentistry. The proposed VR framework is developed by leveraging ray-marching volume rendering in the Unity platform with VR technologies for seamless interactions and to create an improvised immersive visualization environment. user-friendly interface supports intuitive CBCT volume manipulation through hand gestures and handheld controllers using an Oculus Quest 2 VR head-mounted device. A comprehensive evaluation involving 12 medical experts demonstrated the framework’s effectiveness, with an impressive overall mean rating of 4.4 out of 5, emphasizing its favorable reception. Participants were awarded a mean score of 4.3 out of 5 for the VR experience and a remarkable 4.5 out of 5 for performance and interactions, highlighting its robustness. The high System Usability Scale (SUS) scores of 87% for VR experience and its impact and 91% for performance and interaction unequivocally indicate the exceptional acceptance of the Unity-based VR framework for CBCT image visualization among experienced medical experts. Therefore, this study illuminates how the proposed VR framework has the potential to revolutionize pre-surgical planning and decision-making processes in dental surgery, particularly in the realm of oral and maxillofacial surgery, promising improved patient outcomes.
ER  - 

TY  - JOUR
TI  - Dental-YOLO: Alveolar Bone and Mandibular Canal Detection on Cone Beam Computed Tomography Images for Dental Implant Planning
T2  - IEEE Access
SP  - 101483
EP  - 101494
AU  - M. Widiasri
AU  - A. Z. Arifin
AU  - N. Suciati
AU  - C. Fatichah
AU  - E. R. Astuti
AU  - R. Indraswari
AU  - R. H. Putra
AU  - C. Za’in
PY  - 2022
KW  - Implants
KW  - Dentistry
KW  - Bones
KW  - Three-dimensional displays
KW  - Biomedical measurements
KW  - Alveolar bone
KW  - CBCT
KW  - bone measurement
KW  - dental implant planning
KW  - mandibular canal
KW  - object detection
KW  - YOLO
DO  - 10.1109/ACCESS.2022.3208350
JO  - IEEE Access
IS  - 
SN  - 2169-3536
VO  - 10
VL  - 10
JA  - IEEE Access
Y1  - 2022
AB  - In planning a mandibular posterior dental implant, identifying the exact location of the alveolar bone (AB) and mandibular canal (MC) is essential to determine the height and width of the available bone. Cone beam computed tomography (CBCT) is a 3D imaging modality widely used for dental implant planning, which requires a lower radiation dose compared to medical CT and can provide cross-sectional image quality to visualize AB and MC. The radiologist carried out the AB and MC detection processes manually on each section of the CBCT image until the appropriate area was determined for bone measurement. This process is time consuming, and the measurement accuracy depends on the ability and experience of the radiologist. This study proposes an automatic and simultaneous detection system for AB and MC based on 2D grayscale CBCT images, that can simplify and expedite dental implant planning. We introduce Dental-YOLO, an efficient version of YOLOv4 specifically developed to detect AB and MC, with two-scale feature maps at low and high scales. The height and width of the available bone in the implant area were estimated by using the detected bounding box attributes. The AB and MC detection performances using Dental-YOLO reached a mean average precision of 99.46%. The two-way analysis of variance (ANOVA) test showed no difference in the bone height and width measurements produced by the proposed approach and manual measurement by radiologists. Our results suggest that the Dental-YOLO detection system could be helpful for dental implant surgery and presurgical treatment planning.
ER  - 

